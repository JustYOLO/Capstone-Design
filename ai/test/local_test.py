import httpx
import chromadb
import ollama
import ast
import re


client_ko = chromadb.PersistentClient(path="./chromadb_storage_ko")
collection_ko = client_ko.get_or_create_collection(name="flowers_ko")


# def search_flower_ko(situation):
#     # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìƒí™©ì„ ë²¡í„° ì„ë² ë”©
#     query_embedding = ollama.embeddings(model="llama3-ko:latest", prompt=situation)["embedding"]
    
#     # ê°€ì¥ ìœ ì‚¬í•œ ê½ƒë§ì„ ê°€ì§„ ê½ƒ ê²€ìƒ‰
#     results = collection_ko.query(
#         query_embeddings=[query_embedding],
#         n_results=3  # ê²€ìƒ‰í•  ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 3ê°œ ì¶”ì²œ)
#     )
    

#     recommended_flowers = []
#     if results["documents"]:
#         for doc in results["documents"][0]:
#             if ": " in doc:
#                 flower, meaning = doc.split(": ", 1)
#                 recommended_flowers.append((flower.strip(), meaning.strip()))

#     if not recommended_flowers:
#         return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

#     return recommended_flowers



def extract_keywords(situation: str) -> list:
    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ í•µì‹¬ ì˜ë¯¸ë¥¼ ë‹´ì€ ë‹¨ì–´(ì˜ˆ: ê°ì •, ëª©ì , ê´€ê³„ ë“±)ë¥¼ 3ê°œ ì¶”ì¶œí•´ì¤˜. ê¼­ ë¬¸ì¥ ë‚´ ë‹¨ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ë„ ê´œì°®ë‹¤. 
    ë„ˆê°€ ìƒí™©ì„ ìœ ì¶”í•˜ì—¬ ê½ƒ ì¶”ì²œì— ì¤‘ì‹¬ì´ ë˜ëŠ” ë‹¨ì–´ë§Œ ë½‘ì•„ì¤˜. 
    ì´ë•Œ 'ì„ ë¬¼' ë‹¨ì–´ëŠ” ì ˆëŒ€ ë½‘ì§€ë§ˆ.

    ë¬¸ì¥: "{situation}"

    ## ì¶œë ¥ ì˜ˆì‹œ
    - í‚¤ì›Œë“œ: ["ì¡´ê²½", "êµìˆ˜ë‹˜", "ê°ì‚¬"]
    - í‚¤ì›Œë“œ: ["ê°ì‚¬", "ì–´ë²„ì´", "ë¶€ëª¨ë‹˜"]
    - í‚¤ì›Œë“œ: ["ì‚¬ë‘", "ê¸°ë…ì¼", "ì—°ì¸"]

    ë°˜ë“œì‹œ Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´.
    """
    output = ollama.generate(model="gemma3:4b", prompt=prompt)["response"]
    print(f"[í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼]: {output.strip()}")

    try:
        # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë¬¸ìì—´ë§Œ ì¶”ì¶œ
        matches = re.findall(r'"(.*?)"', output)
        return matches
    except Exception as e:
        print(f"[keyword parse error] {e}")
        return []


def search_flower_ko(situation: str) -> list:
    keywords = extract_keywords(situation)
    print(f"[ì¶”ì¶œëœ í‚¤ì›Œë“œ]: {keywords}")

    all_candidates = []
    for keyword in keywords:
        print(f"[ğŸ” ê²€ìƒ‰ ê¸°ì¤€ í‚¤ì›Œë“œ]: {keyword}")
        embedding = ollama.embeddings(model="llama3-ko:latest", prompt=keyword)["embedding"]
        results = collection_ko.query(query_embeddings=[embedding], n_results=10)
        docs = results["documents"][0]
        print(f"[{keyword} í›„ë³´]: {docs}")
        all_candidates.extend(docs)

    # ì¤‘ë³µ ì œê±°
    all_candidates = list(dict.fromkeys(all_candidates))

    flowers_info = "\n".join(all_candidates)
    
    # ìµœì¢… ì¶”ì²œ 3ê°œë¥¼ LLMìœ¼ë¡œ ì¬ì •ë ¬
    prompt = f"""
    ìƒí™©: "{situation}"
    
    ë‹¹ì‹ ì€ ê½ƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ìš”ì²­í•œ ìƒí™©ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ê½ƒì„ ê°ì •ì ìœ¼ë¡œ ì˜ ì¶”ì²œí•´ì£¼ì„¸ìš”.
    ì•„ë˜ëŠ” ì¶”ì²œ í›„ë³´ ê½ƒê³¼ ê·¸ ê½ƒë§ì…ë‹ˆë‹¤.
    ìƒí™©ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ê½ƒ 3ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.

    {flowers_info}

    ## ì¶œë ¥ í˜•ì‹: (ì´ìœ ëŠ” ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)
    - ê½ƒ: ê½ƒë§
    
    ## ì˜ˆì‹œ ì¶œë ¥:
    - ë¶‰ì€ ë™ë°±ê½ƒ: ë‚˜ëŠ” ë‹¹ì‹ ì´ ëˆ„êµ¬ë³´ë‹¤ë„ ì•„ë¦„ë‹µë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.
    - í° ì¥ë¯¸: ë‹¹ì‹ ì˜ ìˆœìˆ˜í•¨ê³¼ ì§„ì‹¤í•¨ì„ ì¡´ê²½í•©ë‹ˆë‹¤.
    - ë…¸ë€ í•´ë°”ë¼ê¸°: ë‹¹ì‹ ì˜ ë°ì€ ì—ë„ˆì§€ê°€ ì£¼ë³€ì„ í™˜í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    """

    response = ollama.generate(model="gemma3:4b", prompt=prompt)["response"]

    final_result = []
    for line in response.strip().split("\n"):
        if ":" in line:
            name, reason = line.split(":", 1)
            final_result.append((name.strip(), reason.strip()))
    return final_result


# def search_flower_ko(situation):
#     query_embedding = ollama.embeddings(model="llama-ko-bllossom-8B:latest", prompt=situation)["embedding"]
    
#     # ìƒìœ„ 10ê°œ ê²€ìƒ‰ í›„ ì˜ë¯¸ í•„í„°ë§
#     results = collection_ko.query(
#         query_embeddings=[query_embedding],
#         n_results=20
#     )

#     candidate_docs = results["documents"][0]
#     if not candidate_docs:
#         return []
    
#     print(candidate_docs)

#     # LLM ì¬ì •ë ¬
#     flowers_info = "\n".join(candidate_docs)
#     rerank_prompt = f"""
#     ìƒí™©: "{situation}"
    
#     ë‹¹ì‹ ì€ ê½ƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ìš”ì²­í•œ ìƒí™©ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ê½ƒì„ ê°ì •ì ìœ¼ë¡œ ì˜ ì¶”ì²œí•´ì£¼ì„¸ìš”.
#     ì•„ë˜ëŠ” ê½ƒê³¼ ê·¸ ê½ƒë§ì…ë‹ˆë‹¤.
#     ìƒí™©ì— ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ê½ƒ 3ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.

#     {flowers_info}

#     ## ì¶œë ¥ í˜•ì‹: (ì´ìœ ëŠ” ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)
#     - ê½ƒ: ê½ƒë§
    
#     ## ì˜ˆì‹œ ì¶œë ¥:
#     - ë¶‰ì€ ë™ë°±ê½ƒ: ë‚˜ëŠ” ë‹¹ì‹ ì´ ëˆ„êµ¬ë³´ë‹¤ë„ ì•„ë¦„ë‹µë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.
#     - í° ì¥ë¯¸: ë‹¹ì‹ ì˜ ìˆœìˆ˜í•¨ê³¼ ì§„ì‹¤í•¨ì„ ì¡´ê²½í•©ë‹ˆë‹¤.
#     - ë…¸ë€ í•´ë°”ë¼ê¸°: ë‹¹ì‹ ì˜ ë°ì€ ì—ë„ˆì§€ê°€ ì£¼ë³€ì„ í™˜í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
#     """
#     output = ollama.generate(model="gemma3:4b", prompt=rerank_prompt)["response"]

#     # print(output)
#     # ê²°ê³¼ íŒŒì‹±
#     recommended_flowers = []
#     for line in output.strip().split("\n"):
#         if line.startswith("- "):  # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ë¼ì¸
#             try:
#                 flower, flower_mean = line[2:].strip().split(":", 1)
#                 recommended_flowers.append((flower.strip(), flower_mean.strip()))
#             except:
#                 continue
#     return recommended_flowers




def generate_flower_recommendation(situation, recommended_flowers):
    """ì¶”ì²œëœ ê½ƒ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ Ollamaë¥¼ ì´ìš©í•´ ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ë¬¸ì¥ ìƒì„±"""
    if not recommended_flowers:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ê½ƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    flowers_info = ", ".join([f"{f}({m})" for f, m in recommended_flowers])
    # print(flowers_info)
    prompt_text = f"""
        You are a flower expert. Recommend a flower that suits the user's situation and logically explain its meaning and the reason for your recommendation.
        The user has requested a flower recommendation for the following situation:

        Situation: {situation}

        Recommended flowers and their meanings: {flowers_info}

        Please provide a kind yet logical response following the format below.

        ## Output Format (Explain logically why you recommended these flowers)
        - Reason for Recommendation: [Logically explain how the flower meaning connects to the user's situation]
    """
    
    # ì‘ë‹µ ìƒì„±
    output = ollama.generate(model="llama3:latest", prompt=prompt_text)
    return output["response"]


def generate_flower_recommendation_ko(situation, recommended_flowers):
    """ì¶”ì²œëœ ê½ƒ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ Ollamaë¥¼ ì´ìš©í•´ ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ì²œ ë¬¸ì¥ ìƒì„±"""
    if not recommended_flowers:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ê½ƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    flowers_info = ", ".join([f"{f}({m})" for f, m in recommended_flowers])
    #print(flowers_info)
    prompt_text = f"""
        You are a flower expert. The user has requested a flower recommendation for the following situation:
        Situation: {situation}

        Here are the recommended flowers and their meanings:
        {flowers_info}

        Please write a kind, heartfelt, and logically clear recommendation that explains how the meanings of these flowers relate to the user's situation.

        ## Output Format
        
        - ì¢…í•© ì¶”ì²œ ì´ìœ :
        [Explain logically and kindly how the combined meanings of the recommended flowers connect specifically to the user's situation.]

        Important Instructions:
        - Provide ONLY the 'ì¢…í•© ì¶”ì²œ ì´ìœ ' section.
        - Do NOT include any other sections or titles.
        - Respond strictly in Korean.
        - And there must be a new line between flower descriptions.
    """
    
    # ì‘ë‹µ ìƒì„±
    output = ollama.generate(model="gemma3:4b", prompt=prompt_text)
    return output["response"]



def format_recommended_flowers(recommended_flowers_ko):
    """ì£¼ì–´ì§„ recommended_flowers_ko ë°ì´í„°ë¥¼ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    formatted_flowers = []
    print(recommended_flowers_ko)
    for flower, reason in recommended_flowers_ko:
        formatted_flowers.append(f"ì¶”ì²œí•˜ëŠ” ê½ƒ: {flower}\nì¶”ì²œí•˜ëŠ” ì´ìœ : {reason}\n")
    return "\n".join(formatted_flowers)



# í…ŒìŠ¤íŠ¸: íŠ¹ì • ìƒí™©ì— ì–´ìš¸ë¦¬ëŠ” ê½ƒ ì¶”ì²œ
if __name__ == "__main__":
    # í•œêµ­ì–´ ì…ë ¥ ë°›ê¸°
    query_text_ko = input("í˜„ì¬ ì–´ë–¤ ìƒíƒœì—ì„œ ê½ƒì„ ì„ ë¬¼í•´ì£¼ê³  ì‹¶ë‚˜ìš”? : ")
    print("")

    recommended_flowers_ko = search_flower_ko(query_text_ko)

    formatted_result = format_recommended_flowers(recommended_flowers_ko)
    print(formatted_result)
    
    # print("")
    
    # print(generate_flower_recommendation_ko(query_text_ko, recommended_flowers_ko))